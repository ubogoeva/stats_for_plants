---
title: "R и статистика в селекции: лекция 5"
subtitle: 'Введение в статистику вывода, тест Стьюдента'
author: "Elena U"
#date: "Created on 01 April, 2023"
execute:
  echo: true
  output: true
format: 
  revealjs:
    slide-number: c/t
    show-slide-number: all
    # mainfont: Arial
    # fontsize: 14px
    theme: [default, custom.scss]
    chalkboard: 
      buttons: true
    # theme: [serif]
    # mouse-wheel: true
    auto-play-media: true
    width: 1280
    height: 720
    fig-dpi: 300
    # logo: figures/icg.png
revealjs-plugins:
  - pointer
css: styles.css
editor: visual
filters: [bg_style.lua]
---

## План лекции

-   Проекты и организация работы в RStudio

-   Нормальное распределение и центральная предельная теорема

-   Алгоритм статистического вывода

-   Разбор алгоритма на примере теста Стьюдента

-   Тест Велча и ограничения теста Стьюдента

-   Тест Манна-Уитни

## Нормальное распределение

Симметричное, унимодальное, где отклонения от среднего подчиняются вероятностному закону.

![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Standard_deviation_diagram.svg/1200px-Standard_deviation_diagram.svg.png){width="522"}

Стандартное нормальное распределение -- нормальное распределение со средним 0 и дисперсией 1. Любое нормальное распределение можно привести к стандартному с помощью z-преобразования.

## Значение центральной предельной теоремы

Мысленный эксперимент: многократно извлекаем выборки из генеральной совокупности, считаем средние по выборкам.

```{r}
samp_means <- replicate(1000, mean(rnorm(100, mean = 100, sd = 15)))  
hist(samp_means, breaks = 30) 
```

Распределение средних, извлеченных из нормального распределения, примерно нормальное. Это неудивительно, попробуем теперь в качестве генеральной совокупности использовать лог-нормальное распределение.

## Лог-нормальное распределение

```{r}
hist(rlnorm(100), breaks = 30) 
```

Распределение ассиметричное, однако как будут распределены выборочные средние?

## Распределение средних лог-нормального распределения {style="font-size: 90%"}

```{r}
samp_means_log <- replicate(1000, mean(rlnorm(100)))  
hist(samp_means_log, breaks = 30)
```

А вот распределение средних из изначально не-нормального распределение тоже похоже на нормальное распределение! Это получается благодаря центральной предельной теореме.

[Шайни апп для центральной предельной теоремы](https://gallery.shinyapps.io/CLT_mean/)

## Алгоритм статистического вывода

1.  Формулировка нулевой и альтернативной гипотезы.

2.  Вычисление тестовых статистик.

3.  Подсчет p-value как площади под кривой выборочного распределения тестовых статистик.

4.  Вывод: отклоняем или не отклоняем нулевую гипотезу.

Разберем на примере теста Стьюдента.

## Тест Стьюдента или t-test

Используется для сравнения двух выборок между собой, в случае когда мы не знаем стандартное отклонение генеральной совокупности (почти всегда). В результате мы оцениваем стандартное отклонение в генеральной совокупности на основе стандартного отклонения по выборке.

Это приводит к тому, что тестовая статистика уже не распределена нормально (как в z-тесте), а распределена согласно t-распределению. Статистика называется t-статистикой.

$$
t = \frac{\overline{x} - \mu} {s_x / \sqrt{N}}
$$

## Распределение Стьюдента или t-распределение

::: columns
::: {.column width="55%"}
t-распределение очень похоже на нормальное, также симметричное, унимодальное, но отклонения от среднего подчиняются немного другому вероятностному закону и зависят от размера выборки.

t-распределение имеет параметр степеней свободы: размер выборки -1 и распределение имеет более "тяжелые" хвосты по сравнению с нормальным.

При размере выборке (и количеству степеней свободы), стремящемуся к бесконечности, t-распределение стремится к нормальному.
:::

::: {.column width="45%"}
![](https://pozdniakov.github.io/tidy_stats/320-ttest_files/figure-html/unnamed-chunk-1-1.png)
:::
:::

# Проведение теста Стьюдента

## Постановка задачи

У нас есть две выборки, мы хотим сравнить средние, и сделать вывод, есть ли статистически значимые различия между ними. Для этого возьмем данные по урожайности растения сафлор.

```{r}
# install.packages('agridat')
library(agridat)
data(draper.safflower.uniformity)
df <- draper.safflower.uniformity
str(df)
```

Здесь два эксперимента: E4 и E5, которые отличались размером делянки. Сравним, есть ли различия в урожайности у двух групп.

Для этого подходит двухвыборочный независимый тест Стьюдента.

## Посмотрим на данные

```{r}
#| output-location: column
library(tidyverse)
df %>% 
  ggplot(aes(expt, yield))+
  geom_boxplot()
```

Размер выборок:

```{r}
summary(df$expt)
```

## Формулировка нулевой и альтернативной гипотезы

\- $H_0: \mu_1 = \mu_2$ нулевая гипотеза, о том, что обе выборки взяты из одной генеральной совокупности (или из генеральных совокупностей с одинаковым средним) (урожайность одинакова вне зависимости от размера делянки).

\- $H_1: \mu_1 \neq \mu_2$ альтернативная гипотеза, о том, что выборки взяты из генеральных совокупностей с разным средним (урожайность различается).

Здесь $\mu_1$ -- среднее генеральной совокупности для эксперимента Е4, $\mu_2$ -- среднее генеральной совокупности для эксперимента E5.

## Вычисление тестовой статистики

Формула расчета для двухвыборочного независимого теста Стьюдента:

$$
t = \frac{\overline{X_1}-\overline{X_2}}{s_x\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}},s_x = \sqrt{\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}
$$

Посчитаем с помощью функции `t.test()` и выберем только значение статистики:

```{r}
t_value <- t.test(yield ~ expt, df, var.equal = TRUE)$statistic
t_value
```

t-статистика равна `-33.66`, чем она больше (по модулю), тем p-value будет ниже.

## Подсчет p-value

Определение: p-value -- это вероятность получить такие же или еще более экстремальные значения тестовой статистики при условии верности нулевой гипотезы.

Распределение тестовой статистики -- это t-распределение с $n_1 + n_2 - 2$ степенями свободы, где $n_1$, $n_2$ -- размер выборки 1 и размер выборки 2, соответственно.

```{r}
#| echo: false
library(ggplot2)
t_distr <- data.frame(x = seq(-40, 40, 0.1), 
                      t = dt(seq(-40, 40, 0.1), 638))
ggplot(t_distr, aes(x, t))+
  # geom_point()+
  geom_line()+
  geom_vline(aes(xintercept = t_value), color = 'blue',
             linetype = 2)+
   geom_vline(aes(xintercept = -t_value), color = 'blue',
             linetype = 2)+
  geom_rect(aes(xmin=-40, xmax=t_value, ymin=0, ymax=0.001), fill = 'blue', alpha = 0.8)+
    geom_rect(aes(xmin=-t_value, xmax=40, ymin=0, ymax=0.001), fill = 'blue', alpha = 0.8)+
  theme_bw()
```

Значение t-статистики очень большое, значит значение p-value очень маленькое.

## Подсчет p-value

Функция `pt()` подсчитывает площадь под кривой распределения от $-\infty$ до `t_value`. Поскольку тест двусторонний, то надо умножить на 2.

```{r}
pt(t_value, df = nrow(df) - 2, lower.tail = TRUE) * 2
```

Теперь сравним с результатом теста `t.test()`

```{r}
t.test(yield ~ expt, df, var.equal = TRUE)$p.value
```

## Принятие решения о нулевой гипотезе

```{r}
t.test(yield ~ expt, df, var.equal = TRUE)
```

p-value \< 0.05 -\> следовательно отклоняем нулевую гипотезу о равенстве средних.

## Тест Стьюдента и тест Велча (Welch)

На самом деле по умолчанию в R запускается тест Велча, который устойчив к нарушению предположения о равенстве дисперсий.

Для запуска теста Стьюдента мы использовали аргумент `var.equal = TRUE`, по умолчанию `FALSE`.

Расчет теста Велча

```{r}
t.test(yield ~ expt, df)
```

## Формула теста Велча

$$
t = \frac{\overline{X}_1 - \overline{X}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}
$$

Количество степеней свободы:

$$
df = \frac{(s_1^2/n_1 + s_2^2 / n_2)^2}{(s_1^2/n_1)^2/(n_1-1) + (s_2^2/n_2)^2/(n_2-1)}
$$

По умолчанию рекомендую считать именно тест Велча, потому что для случаев, где дисперсии двух выборок приблизительно равны, он не будет отличаться от теста Стьюдента, а при разных дисперсиях точнее.

## Ограничения теста Стьюдента

::: incremental
-   Независимость наблюдений - очень важно.

-   Нормальность распределения - под вопросом.

-   Равенство дисперсий - необязательно для теста Велча.
:::

## Нужно ли нормальное распределение для t-теста?

Давайте сначала оценим вероятность ошибки первого рода, когда мы многократно (10000 раз) извлекаем две выборки объемом 30 значений из стандартного нормального распределения и сравниваем их t-тестом:

Генеральная совокупность одинаковая, следовательно мы ожидаем найти отличия не более чем в 5% случаев.

```{r}
mean(replicate(10000, t.test(rnorm(30), rnorm(30))$p.value) < 0.05)
```

Вероятность получить ошибку первого рода (то есть найти отличия, там где их на самом деле нет) примерно 0.05.

Ссылки: [1](#0), [2](#0).

## Теперь такую же процедуру для логнормального распределения

Генеральная совокупность одинаковая, следовательно мы ожидаем найти отличия не более чем в 5% случаев.

```{r}
mean(replicate(10000, t.test(rlnorm(30), rlnorm(30))$p.value) < 0.05)

```

Вероятность ошибки первого рода даже меньше!

Что насчет графического способа определения нормальности распределения?

## Попробуем отрисовать qqplot для нормального распределения

qqplot - quantile-quantile plot.

```{r}
library(car)
set.seed(50)
samp <- rnorm(30)
qqPlot(samp)
```

В нормальном распределении точки должны располагаться на синей линии.

## Попробуем отрисовать гистограмму

```{r}
hist(samp)

```

Вывод: не всегда графический способ позволяет определить принадлежность данных нормальному распределению, поскольку при малых объемах выборки даже настоящее нормальное распределение может не выглядеть как нормальное.

## Тест Шапиро-Уилка (Shapiro-Wilk) для проверки на нормальность

```{r}
shapiro.test(samp)

```

В нашем случае p-value больше 0.05, что логично: мы взяли эту выборку именно из нормального распределения. Если p-value меньше уровня α, который у нас стандартно 0.05, то мы можем отвергнуть нулевую гипотезу о том, что выборка взята из нормального распределения.

::: callout-warning
Однако тест Шапиро-Уилка это такой же статистический тест, как и другие, следовательно, чем больше выборка, тем с большей вероятностью он найдет отклонения от нормальности.
:::

## Непараметрические тесты

Тем не менее, бывают ситуации, когда тест Стьюдента неприменим, например в случае явных выбросов. В таком случае можно использовать непараметрический аналог - тест Манна-Уитни.

Кроме того, непараметрические методы подходят для интервальных и ранговых шкал, где арифметическое среднее не имеет физического смысла.

Непараметрические тесты не опираются на *параметры* заранее известных распределений (например нормального), следовательно, более устойчивы к нарушению предположений параметрических тестов.

## Тест Манна-Уитни (Mann-Whitney): теория

$H_0: P(A > B) = 0.5$ вероятность того, что случайное число из распределения *A* больше, чем случайное число из распределения *B* равно 50%.

$H_1: P(A > B) \neq 0.5$ вероятность, что случайное число из *A* больше чем *B* не равно 50%, следовательно распределения *A* и *B* отличаются сдвигом местоположения.

Иллюстрация:

```{r}
#| echo: false
df_vis <- data.frame(A = rnorm(1000, 0, 1), B = rnorm(1000, 2, 1))
df_vis %>% 
  pivot_longer(cols = A:B) %>% 
  ggplot(aes(value, fill = name))+
  geom_histogram(binwidth = 0.5, alpha = 0.5, color = 'black', position = 'identity')+
  scale_fill_manual(values=c("seagreen", "orange")) + 
  # theme_bw()+
  theme_classic()
```

## Тест Манна-Уитни (Mann-Whitney): формула

Числа из обеих выборок ранжируются, то есть расставляются по порядку и самому наименьшему числу присваивается ранг 1, следующему 2, и так далее. Затем вычисляется тестовая U-статистика.

Для независимых выборок - функция `wilcox.test()`, синтаксис такой же как и для `t.test()`:

```{r}
wilcox.test(yield ~ expt, df)
```

p-value \< 0.05 -\> отклоняем нулевую гипотезу о "равенстве распределений".

## Чек-лист

-   Нормальное распределение и центральная предельная теорема

-   t-распределение

-   Алгоритм статистического вывода

-   Ограничения теста Стьюдента
