---
title: "R и статистика в селекции: лекция 8"
subtitle: 'Тест Стьюдента, ANOVA и линейная регрессия как частные случаи общей линейной модели. Введение в обобщенную линейную модель.'
author: "Elena U"
#date: "Created on 01 April, 2023"
execute:
  echo: true
  output: true
format: 
  revealjs:
    slide-number: c/t
    show-slide-number: all
    # mainfont: Arial
    # fontsize: 14px
    theme: [default, custom.scss]
    chalkboard: 
      buttons: true
    # theme: [serif]
    # mouse-wheel: true
    auto-play-media: true
    width: 1280
    height: 720
    fig-dpi: 300
    # logo: figures/icg.png
revealjs-plugins:
  - pointer
css: styles.css
editor: visual
filters: [bg_style.lua]
---

## Вспомним, что было в предыдущих лекциях

-   Тест Стьюдента

-   Линейная регрессия

    -   Простая линейная регрессия

    -   Множественная линейная регрессия

    -   Ограничения линейной регрессии

-   Однофакторный дисперсионный анализ (ANOVA)

## План лекции

-   Ограничения ANOVA

-   Post-hoc тесты

-   Непараметрические аналоги ANOVA (и постхоки)

-   Двухфакторная ANOVA

-   t-test и ANOVA как частные случаи линейной регрессии

## Данные для работы

Данные об урожайности различных культур.

```{r}
library(tidyverse)
library(agridat)
data("bose.multi.uniformity")
df_anova <- bose.multi.uniformity
str(df_anova)
```

Будем сравнивать урожайность пшеницы, ячменя и чечевицы.

Переменная `crop` записана в виде фактора, если бы это было не так, нужно было бы превратить ее в фактор (это будет важно в дальнейшем).

Фактор -- проименованный вектор в R. По умолчанию уровни заданы в алфавитном порядке.

## Ограничения ANOVA

-   Независимость наблюдений.

-   Нормальность распределения исходных данных - под вопросом (тоже самое, что и про t-test).

-   Равенство дисперсий исходных данных - необязательно, если дизайн сбалансированный.

-   **Нормальность распределения остатков** -- очень важно.

-   **Равенство дисперсии распределения остатков**.

## Что такое остатки в ANOVA?

Дисперсионный анализ можно воспринимать как частный случай линейной модели, когда зависимая переменная количественная, а независимая номинативная.

```{r}
#| echo: false
df_mean <- df_anova %>% group_by(crop) %>% summarise(mean = mean(yield)) %>% as.data.frame()
ggplot(df_anova, aes(crop, yield, color = crop))+   
  geom_jitter(alpha = 0.6, size = 1, width = 0.2)+
  geom_segment(aes(y = df_mean[1,2], yend = df_mean[1,2], x = 0.75, xend = 1.25), color = '#66c2a5', linewidth = 2)+   
  geom_segment(aes(y = df_mean[2,2], yend = df_mean[2,2], x = 1.75, xend = 2.25), color = '#fc8d62', linewidth = 2)+   
  geom_segment(aes(y = df_mean[3,2], yend = df_mean[3,2], x = 2.75, xend = 3.25), color = '#8da0cb', linewidth = 2)+   
  scale_color_manual(values = c('#66c2a5', '#fc8d62', '#8da0cb'))+   
  theme_bw() 
```

## Проведем дисперсионный анализ

**1 этап: формулировка нулевой и альтернативной гипотезы.**

H~0~: все средние равны. $\mu_1 = \mu_2 = \mu_3$

H~1~: хотя бы одно среднее не равно остальным. $\mu_i \neq \mu_j$

Проведем однофакторную анову:

```{r}
fit <- aov(yield ~ crop, data = df_anova)
summary(fit)
```

Как минимум в одной паре средние не равны, но мы не знаем, какие именно средние. Чтобы это узнать, нужно сделать постхок тест.

## Поправка Тьюки (Tukey)

$$ q_s = \frac{M_1 - M_2}{\sqrt{\frac{SS_w}{2}(\frac{1}{n_A}+\frac{1}{n_B})}},  $$

где M~1~ \> M~2~ (средние в группе), *nA*, *nB* - размер 1 и 2 выборки, SS~W~ - внутригрупповая сумма квадратов в ANOVA.

Для проверки гипотезы используется studentized range distribution, студентизированное распределение.

Тестируется сравнение средних каждой группы с каждой, необязательно использовать *только* после значимой ановы (однако в тесте используется SS~W~ и количество степеней свободы из таблицы ановы).

## Поправка Тьюки в R

```{r}
TukeyHSD(fit)
```

Все группы значимо различаются между собой.

Нужно проверить, что условия применимости дисперсионного анализа были выполнены.

## Проверка на нормальность распределения остатков

Гистограмма

```{r}
hist(residuals(fit)) 
```

Распределение остатков похоже на нормальное.

## QQ-plot

```{r}
car::qqPlot(residuals(fit))
```

В целом, условия применимости дисперсионного анализа выполнены.

Если условия нарушаются, то есть смысл использовать непараметрические аналоги.

## Непараметрический аналог ANOVA -- тест Краскелла-Уоллиса (Kruskal-Wallis)

Очень похож на тест Манна-Уитни, но применим для нескольких групп.

```{r}
kruskal.test(yield ~ crop, df_anova)
```

## Постхок тест Данна (Dunn)

Для обычной ановы используем Тьюки, но в случае нарушения предположений ановы, нарушается и предположения Тьюки, следовательно, для сравнения групп нужно использовать другие тесты.

Непараметрические аналоги Тьюки: тест Даннета (Dunnet), тест Данна (Dunn).

```{r}
rstatix::dunn_test(df_anova, yield ~ crop)
```

Делается сравнение каждой группы с каждой и поправка по методу Холма (по умолчанию).

## Тест Даннета (Dunnet)

Тестирует сравнение контроля с остальными группами, используется в ситуации, когда не нужно сравнение каждой группы с каждой.

Делает сравнение каждой группы с группой, которую мы назовем контрольной.

```{r}
library(DescTools)
DunnettTest(df_anova$yield, df_anova$crop, control = 'wheat')
```

## Двухфакторный дисперсионный анализ

Влияние единственного фактора редко когда интересует исследователя. Гораздо чаще нас интересует влияние нескольких факторов, и особенно их возможное взаимодействие.

Допустим, мы хотим сравнить урожайность различных сортов в зависимости от времени посева. Например, у нас две независимые переменные: сорт (3 уровня фактора) и время посева (3 уровня фактора). Часто обозначают как "3x3 ANOVA".

Мы можем оценить влияние каждого фактора по отдельности, и, самое интересное, -- их возможное взаимодействие.

## Что такое взаимодействие факторов?

Взаимодействие факторов -- когда эффект фактора A разный в зависимости от фактора B и наоборот. На каких рисунках есть взаимодействие факторов?

![Logan, 2010, fig.12.2](https://varmara.github.io/linmodr/images/interaction.png){alt="Logan, 2010, fig.12.2"}

## Двухфакторный дисперсионный анализ: данные

```{r}
library(readxl)
df_two_way <- read_xlsx('Wheat_density_terms.xlsx')
str(df_two_way)
df_two_way$DENSITY <- as.factor(df_two_way$DENSITY)
df_two_way$REP <- as.factor(df_two_way$REP)
```

## Визуализация данных

Взаимодействие видно на графике с линиями: если линии параллельны, то взаимодействия нет.

```{r}
#| echo: false
# diet <- diet %>%
  # mutate(genderf = factor(gender, labels = c("ж", "м"))) #превращаем в бинарную переменную в фактор

sem <- function(x) sd(x)/sqrt(length(x)) # пишем функцию для стандартной ошибки
pd <- position_dodge(0.05) # немного раздвигаем положение точек на будущем графике
df_two_way %>%
  group_by(VARIETY, TERM) %>%
  summarise(meanloss = mean(YIELD),
            se = sem(YIELD)) %>%
  ggplot(aes(x = VARIETY, 
             y = meanloss, 
             colour = TERM)) +
  geom_line(aes(group = TERM), position = pd) +
  geom_pointrange(aes(ymin = meanloss - se, 
                      ymax = meanloss + se), position = pd) +
  theme_bw()
```

## Запуск дисперсионного анализа

```{r}
library(rstatix)
anova_test(df_two_way, YIELD ~ VARIETY * TERM)
```

Для двухфакторной ановы не рекомендуется использовать функцию `aov()` из базового R, потому что при несбалансированном дизайне расчет может получиться некорректным.

## Важность сбалансированности данных {style="font-size: 90%"}

Если данные сбалансированы (размеры групп примерно одинаковы), то

-   взаимодействие и эффекты факторов независимы (в любой параметризации),

-   все суммы квадратов и соответствующие тесты можно посчитать в одном анализе,

-   результат не зависит от порядка включения факторов в модель.

Если данные несбалансированы, то

-   суммы квадратов для факторов не равны общей сумме квадратов,

-   для вычислений используется регрессионный подход (несколько сравнений вложенных моделей),

-   результат анализа может зависеть от порядка включения факторов в модель.

# t-test и ANOVA как частные случаи линейной модели 

## Общая линейная модель (general linear model)

$$ Y = XB + U, $$

где $Y$ - матрица зависимых переменных, $X$ - матрица независимых переменных, $B$ - матрица оцененных параметров, $U$ - матрица ошибок (остатков).

Почти все пройденные нами методы можно рассматривать как частный случай общей линейной модели: t-тесты, коэффициент корреляции Пирсона, линейная регрессия, ANOVA.

![](https://lindeloev.github.io/tests-as-linear/linear_tests_cheat_sheet.png)

Картинка побольше [здесь](https://lindeloev.github.io/tests-as-linear/).

## Обобщенная линейная модель (generalized linear model, GLM)

Обобщенная линейная модель была придумана как обобщение линейной регрессии и ее сородичей: логистической регрессии и пуассоновской регрессии.

Обобщенную линейную модель можно использовать, когда распределение ошибок отличается от нормального.

![](https://www.researchgate.net/publication/275248713/figure/fig3/AS:282627568357394@1444395071361/Relationship-between-statistical-models-T-tests-ANOVA-regression-and-ANCOVA-are-all.png){width="553"}

## Практика в R

Проверим, что t-test действительно можно запускать с помощью функции `lm()`.

```{r}
df_filtered <- df_anova %>% 
  filter(crop %in% c('lentil', 'wheat'))
t.test(yield ~ crop, df_filtered, var.equal = TRUE)$p.value # обычный т-тест

l <- summary(lm(yield ~ crop, df_filtered))
l
```

## Dummy coding

Допустим, у нас есть столбец с фактором, у которого 3 уровня.

Можно ли его использовать в качестве бинарного предиктора для регрессии?

. . .

Создаем дополнительные переменные, заполненные нулями и единицами, соответственно фактору.

| factor | A   | B   | C   |
|--------|-----|-----|-----|
| A      | 1   | 0   | 0   |
| A      | 1   | 0   | 0   |
| B      | 0   | 1   | 0   |
| B      | 0   | 1   | 0   |
| C      | 0   | 0   | 1   |
| C      | 0   | 0   | 1   |

Если нам известно 2 столбца, то мы можем однозначно вывести третий.

## Dummy coding {style="font-size: 90%"}

Один из уровней фактора (обычно первый) берется за дефолтный, поскольку на основании оставшихся двух столбцов можно однозначно вывести столбец А.

| B   | C   |
|-----|-----|
| 0   | 0   |
| 0   | 0   |
| 1   | 0   |
| 1   | 0   |
| 0   | 1   |
| 0   | 1   |

Фактор - проименованный вектор в R. По умолчанию уровни заданы в алфавитном порядке.

## ANOVA как общий случай линейной регрессии: графически

```{r}
#| echo: false 
ggplot(df_anova, aes(crop, yield, color = crop))+   
  geom_jitter(alpha = 0.6, size = 1, width = 0.2)+
  geom_segment(aes(y = df_mean[1,2], yend = df_mean[1,2], x = 0.75, xend = 1.25), color = '#66c2a5', linewidth = 2)+   
  geom_segment(aes(y = df_mean[2,2], yend = df_mean[2,2], x = 1.75, xend = 2.25), color = '#fc8d62', linewidth = 2)+   
  geom_segment(aes(y = df_mean[3,2], yend = df_mean[3,2], x = 2.75, xend = 3.25), color = '#8da0cb', linewidth = 2)+   
  scale_color_manual(values = c('#66c2a5', '#fc8d62', '#8da0cb'))+   
  theme_bw() 
```

## Чек-лист пройденного

-   Ограничения ANOVA

-   Пост-хок тесты

-   Непараметрические аналоги

-   Двухфакторный дисперсионный анализ

-   Общая линейная модель
